{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweety-ns\n",
    "%pip install https://github.com/mahrtayyab/tweety/archive/main.zip --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweety import Twitter\n",
    "import asyncio\n",
    "import os\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object AuthMethods.load_auth_token at 0x0000027A0B5A8D00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# auth_token = os.getenv(\"auth_token1\")\n",
    "\n",
    "# # Cookies can be a str or a dict\n",
    "\n",
    "# app = Twitter(\"session\")\n",
    "# app.load_auth_token(auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def login():\n",
    "    # Read username and password from environment variables\n",
    "    username = os.getenv(\"USERNAMEE\")\n",
    "    password = os.getenv(\"PASSWORD\")\n",
    "\n",
    "    if not username or not password:\n",
    "        raise ValueError(\"USERNAMEE or PASSWORD is not configured in the .env file\")\n",
    "\n",
    "    # Initialize Twitter client\n",
    "    app = Twitter(\"session\")\n",
    "    await app.sign_in(username, password)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = await login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_tweets_from_KOLs(input_file_path, output_file_path, app, pages=1, replies=False, wait_time=2, cursor=None):\n",
    "    tweets_data = []\n",
    "\n",
    "    # Read the input file and get the list of screen names\n",
    "    with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        screen_names = [row['screen_name'] for row in reader]\n",
    "\n",
    "    # Open the error file to log users with rate limit errors\n",
    "    with open(\"crawl_user_tweets_error.txt\", mode=\"a\", encoding=\"utf-8\") as error_file:\n",
    "        # Loop through each screen name to fetch tweets\n",
    "        for screen_name in screen_names:\n",
    "            print(f\"Fetching tweets for user: {screen_name}\")\n",
    "            try:\n",
    "                all_tweets = await app.get_tweets(\n",
    "                    username=screen_name,\n",
    "                    pages=pages,\n",
    "                    replies=replies,\n",
    "                    wait_time=wait_time,\n",
    "                    cursor=cursor\n",
    "                )\n",
    "\n",
    "                for tweet in all_tweets:\n",
    "                    tweets_data.append({\n",
    "                        'id': tweet.id,\n",
    "                        'created_on': tweet.created_on,\n",
    "                        'date': tweet.date,\n",
    "                        'text': tweet.text,\n",
    "                        'rich_text': tweet.rich_text.text if tweet.rich_text else None,\n",
    "                        'author': tweet.author.username if tweet.author else None,\n",
    "                        'is_retweet': tweet.is_retweet,\n",
    "                        'retweeted_tweet_id': tweet.retweeted_tweet.id if tweet.is_retweet else None,\n",
    "                        'is_quoted': tweet.is_quoted,\n",
    "                        'quoted_tweet_id': tweet.quoted_tweet.id if tweet.is_quoted else None,\n",
    "                        'is_reply': tweet.is_reply,\n",
    "                        'replied_to': tweet.replied_to.id if tweet.is_reply else None,\n",
    "                        'is_sensitive': tweet.is_sensitive,\n",
    "                        'reply_counts': tweet.reply_counts,\n",
    "                        'quote_counts': tweet.quote_counts,\n",
    "                        'bookmark_count': tweet.bookmark_count,\n",
    "                        'views': tweet.views,\n",
    "                        'likes': tweet.likes,\n",
    "                        'language': tweet.language,\n",
    "                        'place': tweet.place.name if tweet.place else None,\n",
    "                        'retweet_counts': tweet.retweet_counts,\n",
    "                        'source': tweet.source,\n",
    "                        'has_moderated_replies': tweet.has_moderated_replies,\n",
    "                        'is_liked': tweet.is_liked,\n",
    "                        'is_retweeted': tweet.is_retweeted,\n",
    "                        'can_reply': tweet.can_reply,\n",
    "                        'broadcast': tweet.broadcast.title if tweet.broadcast else None,\n",
    "                        'edit_control': tweet.edit_control,\n",
    "                        'has_newer_version': tweet.has_newer_version,\n",
    "                        'audio_space_id': tweet.audio_space_id,\n",
    "                        'pool': tweet.pool.title if tweet.pool else None,\n",
    "                        'community': tweet.community.name if tweet.community else None,\n",
    "                        'media': [media.url for media in tweet.media],\n",
    "                        'user_mentions': [mention.username for mention in tweet.user_mentions],\n",
    "                        'urls': [url.url for url in tweet.urls],\n",
    "                        'hashtags': [hashtag.text for hashtag in tweet.hashtags],\n",
    "                        'symbols': [symbol.text for symbol in tweet.symbols],\n",
    "                        'community_note': tweet.community_note,\n",
    "                        'url': tweet.url,\n",
    "                        'threads': [thread.id for thread in tweet.threads],\n",
    "                        'comments': [comment.id for comment in tweet.comments]\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching tweets for user {screen_name}: {e}\")\n",
    "                \n",
    "                # If rate limit error occurs, log the username to the error file and stop\n",
    "                if 'rate limit' in str(e).lower():\n",
    "                    error_file.write(f\"Rate limit error with user {screen_name}: {e}\\n\")\n",
    "                    break  # Stop immediately after encountering rate limit error\n",
    "\n",
    "        # Check if the output file exists\n",
    "        file_exists = os.path.isfile(output_file_path)\n",
    "\n",
    "        # Save the results to the CSV file (append if the file exists, otherwise write header)\n",
    "        with open(output_file_path, mode='a' if file_exists else 'w', newline='', encoding='utf-8') as outfile:\n",
    "            fieldnames = [\n",
    "                'id', 'created_on', 'date', 'text', 'rich_text', 'author', 'is_retweet', 'retweeted_tweet_id',\n",
    "                'is_quoted', 'quoted_tweet_id', 'is_reply', 'replied_to', 'is_sensitive', 'reply_counts',\n",
    "                'quote_counts', 'bookmark_count', 'views', 'likes', 'language', 'place', 'retweet_counts',\n",
    "                'source', 'has_moderated_replies', 'is_liked', 'is_retweeted', 'can_reply', 'broadcast',\n",
    "                'edit_control', 'has_newer_version', 'audio_space_id', 'pool', 'community', 'media', \n",
    "                'user_mentions', 'urls', 'hashtags', 'symbols', 'community_note', 'url', 'threads', 'comments'\n",
    "            ]\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Write header only if the file does not exist\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerows(tweets_data)\n",
    "\n",
    "        print(f\"Saved {len(tweets_data)} tweets to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic Tweet Information\n",
    "# 'id': int                # The unique ID of the tweet (assigned by Twitter).\n",
    "# 'created_on': datetime   # The date and time when the tweet was created.\n",
    "# 'date': datetime         # The date and time when the tweet was created (same as created_on).\n",
    "\n",
    "# # Main Content of the Tweet\n",
    "# 'text': str              # The text content of the tweet (original text).\n",
    "# 'rich_text': RichText    # The rich text content (if any), which may include HTML formatting or other styles.\n",
    "# 'author': User           # The user object containing information about the tweet's author (e.g., username, ID, etc.).\n",
    "\n",
    "# # Tweet Interaction (Retweets, Quotes, Replies)\n",
    "# 'is_retweet': bool              # If `True`, the tweet is a retweet of another tweet.\n",
    "# 'retweeted_tweet_id': int       # The ID of the original tweet that was retweeted (if applicable).\n",
    "# 'is_quoted': bool               # If `True`, the tweet is a quoted tweet.\n",
    "# 'quoted_tweet_id': int          # The ID of the tweet that was quoted (if applicable).\n",
    "# 'is_reply': bool                # If `True`, the tweet is a reply to another tweet.\n",
    "# 'replied_to': Tweet | str       # The tweet being replied to (if applicable), or the user ID if it is a reply to a user.\n",
    "\n",
    "# # Sensitive Content Information\n",
    "# 'is_sensitive': bool            # If `True`, the tweet contains sensitive content (e.g., graphic images, NSFW).\n",
    "\n",
    "# # Engagement Metrics\n",
    "# 'reply_counts': int            # The number of times someone has replied to this tweet.\n",
    "# 'quote_counts': int            # The number of times this tweet has been quoted.\n",
    "# 'bookmark_count': int          # The number of times this tweet has been bookmarked.\n",
    "# 'views': int                   # The number of times this tweet has been viewed.\n",
    "# 'likes': int                   # The number of likes (favorites) this tweet has received.\n",
    "# 'language': str                # The language of the tweet as identified by Twitter (e.g., 'en' for English).\n",
    "# 'place': Place                 # The location or place associated with the tweet, if available.\n",
    "\n",
    "# # Retweet Information\n",
    "# 'retweet_counts': int          # The number of times this tweet has been retweeted.\n",
    "\n",
    "# # Source and Moderation Information\n",
    "# 'source': str                  # The source application used to post the tweet (e.g., \"Twitter Web App\").\n",
    "# 'has_moderated_replies': bool  # If `True`, replies to the tweet are moderated by the author.\n",
    "\n",
    "# # User Interaction Information\n",
    "# 'is_liked': bool               # If `True`, the authenticated user has liked this tweet.\n",
    "# 'is_retweeted': bool           # If `True`, the authenticated user has retweeted this tweet.\n",
    "# 'can_reply': bool              # If `True`, the authenticated user is allowed to reply to this tweet.\n",
    "\n",
    "# # Broadcast and Edit Information\n",
    "# 'broadcast': Broadcast | None  # Information about the broadcast (if the tweet is part of a broadcast).\n",
    "# 'edit_control': EditControl | None  # Information about the tweet's edit control (if it has been edited).\n",
    "# 'has_newer_version': bool      # If `True`, this tweet has been edited, and there is a newer version of it.\n",
    "\n",
    "# # Additional Tweet Metadata\n",
    "# 'audio_space_id': str          # The ID of the Audio Space associated with the tweet (if applicable).\n",
    "# 'pool': Pool | None            # The pool associated with the tweet (if applicable).\n",
    "# 'community': Community | None  # The community this tweet is a part of (if applicable).\n",
    "\n",
    "# # Media and Mentions\n",
    "# 'media': list[Media]          # A list of media objects (e.g., images, videos) attached to the tweet.\n",
    "# 'user_mentions': list[ShortUser]  # A list of users mentioned in the tweet.\n",
    "# 'urls': list[URL]             # A list of URLs mentioned in the tweet.\n",
    "# 'hashtags': list[Hashtag]      # A list of hashtags mentioned in the tweet.\n",
    "# 'symbols': list[Symbol]       # A list of symbols (e.g., stock symbols) mentioned in the tweet.\n",
    "\n",
    "# # Community and Thread Information\n",
    "# 'community_note': str | None   # A community note posted in response to the tweet (if applicable).\n",
    "# 'url': str                     # The URL of the tweet.\n",
    "# 'threads': list[Tweet]         # A list of tweets in the thread of this tweet.\n",
    "# 'comments': list[ConversationThread]  # A list of replies or comments sent in response to this tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tweets for user: JSDRAM\n",
      "Saved 18 tweets to final_tweet.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file_path = \"KOL_profile_status_count_more_than_200.csv\"\n",
    "output_file_path =\"final_tweet.csv\"\n",
    "await crawl_tweets_from_KOLs(input_file_path, output_file_path, app, pages=10, replies=False, wait_time=2, cursor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def clean_csv(input_file, output_file, column_b_values, column_bio):\n",
    "#     # Đọc file CSV vào DataFrame\n",
    "#     df = pd.read_csv(input_file)\n",
    "\n",
    "#     # Xóa các hàng có giá trị trong cột 'b' nằm trong danh sách column_b_values\n",
    "#     df_cleaned = df[~df['id'].isin(column_b_values)]\n",
    "    \n",
    "#     # Xóa các hàng không có giá trị cho cột 'bio'\n",
    "#     df_cleaned = df_cleaned[df_cleaned['bio'].notna()]\n",
    "\n",
    "#     # Lưu DataFrame đã làm sạch vào file mới\n",
    "#     df_cleaned.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "# # Read keywords from a text file\n",
    "# def read_keywords_from_file(file_path):\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         return [line.strip() for line in file if line.strip()]\n",
    "# # Danh sách các giá trị trong cột 'b' mà bạn muốn xóa\n",
    "# X = read_keywords_from_file(\"loc.txt\")\n",
    "\n",
    "# # Gọi hàm với file đầu vào và đầu ra\n",
    "# clean_csv('KOL_profile_status_count_more_than_200.csv', 'cleaned_KOL_profile_status_count_more_than_200.csv', X, 'bio')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
